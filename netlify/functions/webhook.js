const fetch = (...args) => import('node-fetch').then(({default: fetch}) => fetch(...args));
const OpenAI = require('openai');
const { createClient } = require('@supabase/supabase-js');

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
const supabase = createClient(
  process.env.NEXT_PUBLIC_SUPABASE_URL,
  process.env.SUPABASE_SERVICE_ROLE_KEY
);

const promptBase = `
ROL Y OBJETIVO
Eres un asesor de ventas experto de una llantera. Tu especialidad son las llantas para autos y camionetas. Eres calmado, directo, eficiente y muy resolutivo.

FILOSOF√çA DE CONVERSACI√ìN Y REGLAS CR√çTICAS
1. M√∫ltiples Mensajes Cortos: Habla como en WhatsApp. Divide tus respuestas en burbujas de chat concisas.
2. Sin Presentaciones Innecesarias: NO digas qui√©n eres. Solo responde con amabilidad y claridad.
3. Foco Absoluto en Llantas Automotrices: Si piden llantas de moto, bici o tractor, responde: "Una disculpa, solo manejamos llantas para auto y camioneta."
4. Econom√≠a de Palabras: S√© breve.
5. Detector de Trolls: Si hay insultos o bromas, responde exactamente: [END_CONVERSATION]
6. Detecta medidas aunque est√©n mal escritas: Interpreta cosas como "250 -40 rin 18" y convi√©rtelas a ###/##R##
7. Siempre menciona que los precios est√°n en pesos mexicanos.
8. Cuando invoques buscarInventarioCliente, devuelve EXACTAMENTE el formato JSON: {"medida":"###/##R##"}

JERARQU√çA DE RESPUESTA
1. Si la consulta es inv√°lida, aclara tus l√≠mites.
2. Si detectas una medida v√°lida o deducible: llama a buscarInventarioCliente({ medida })
3. Si no hay stock local: busca medidas compatibles autom√°ticamente.
4. Si tampoco existen compatibles: se consulta red_favoritos (por ahora desactivado).

RESPUESTAS
Habla como humano. No inventes llantas. S√© √∫til y directo.
`;

const delay = (ms) => new Promise((resolve) => setTimeout(resolve, ms));

exports.handler = async (event, context) => {
  if (event.httpMethod !== 'POST') {
    return { statusCode: 405, body: 'Method not allowed' };
  }

  const body = JSON.parse(event.body);
  const entry = body.entry?.[0];
  const messaging = entry?.messaging?.[0];
  const psid = messaging?.sender?.id;
  const pageId = messaging?.recipient?.id;
  const messageText = messaging?.message?.text?.trim();

  if (!psid || !messageText || !pageId) {
    return { statusCode: 400, body: 'Invalid request' };
  }

  // Buscar cliente_id por PSID
  let clienteId = null;
  const { data: userData } = await supabase
    .from('messenger_users')
    .select('cliente_id')
    .eq('psid', psid)
    .maybeSingle();

  if (userData?.cliente_id) {
    clienteId = userData.cliente_id;
  } else {
    const { data: clienteData } = await supabase
      .from('clientes')
      .select('cliente_id')
      .eq('facebook_page_id', pageId)
      .maybeSingle();

    clienteId = clienteData?.cliente_id || 'C0000';

    await supabase.from('messenger_users').insert([
      {
        psid,
        cliente_id: clienteId,
        created_at: new Date().toISOString(),
      },
    ]);

    console.log(`üÜï Nuevo PSID registrado: ${psid} vinculado a cliente ${clienteId}`);
  }

  console.log(`‚úÖ Cliente detectado: ${clienteId} para PSID: ${psid}`);

  const { data: nuevaConversacion } = await supabase
    .from('mensajes')
    .insert({
      cliente_id: clienteId,
      mensaje: messageText,
      quien_hablo: 'cliente',
      sender_id: psid,
    })
    .select('conversacion_id')
    .single();

  const contexto = [
    { role: 'system', content: promptBase },
    { role: 'user', content: messageText },
  ];

  let respuestaIA = await openai.chat.completions.create({
    model: process.env.OPENAI_MODEL || 'gpt-4',
    messages: contexto,
    temperature: 0.7,
  });

  let textoGenerado = respuestaIA.choices?.[0]?.message?.content || '...';

  const match = textoGenerado.match(/\[buscarInventarioCliente\((.*?)\)\]/);

  if (match) {
    console.log('üß† Se detect√≥ llamada a buscarInventarioCliente');
    const argTexto = match[1];

    let medidaSolicitada = null;
    try {
      const argObj = JSON.parse(argTexto.replace(/'/g, '"'));
      medidaSolicitada = argObj?.medida;
    } catch (e) {
      console.error('‚ö†Ô∏è No se pudo parsear la medida:', e);
    }

    let textoLlantas = '';
    let alternativaUsada = false;

    if (medidaSolicitada) {
      const { data: stockExacto } = await supabase.rpc('buscar_llantas_anon', {
        medida: medidaSolicitada,
        clienteid: clienteId,
      });

      if (stockExacto?.length > 0) {
        textoLlantas = stockExacto
          .map(
            (llanta) =>
              `‚Ä¢ ${llanta.marca} ${llanta.medida} ‚Äì ${llanta.estado_fisico} ‚Äì ${llanta.precio} pesos`
          )
          .join('\n\n');
      } else {
        console.log('‚ùå Sin stock exacto. Buscando compatibles...');

        const { data: alternativas } = await supabase
          .from('medidas_compatibles')
          .select('medida_alternativa')
          .eq('medida_original', medidaSolicitada);

        for (const alt of alternativas || []) {
          const medidaAlt = alt.medida_alternativa;
          const { data: stockAlt } = await supabase.rpc('buscar_llantas_anon', {
            medida: medidaAlt,
            clienteid: clienteId,
          });

          if (stockAlt?.length > 0) {
            alternativaUsada = true;
            textoLlantas = `No tenemos la medida ${medidaSolicitada}, pero esta medida compatible tambi√©n le queda a tu veh√≠culo:\n\n`;

            textoLlantas += stockAlt
              .map(
                (llanta) =>
                  `‚Ä¢ ${llanta.marca} ${llanta.medida} ‚Äì ${llanta.estado_fisico} ‚Äì ${llanta.precio} pesos`
              )
              .join('\n\n');

            break;
          }
        }

        if (!alternativaUsada) {
          textoLlantas = `Por ahora no tenemos la medida ${medidaSolicitada}, ni una compatible en este momento.`;
        }
      }

      const contexto2 = [
        { role: 'system', content: promptBase },
        { role: 'user', content: messageText },
        { role: 'assistant', content: textoGenerado },
        {
          role: 'function',
          name: 'buscarInventarioCliente',
          content: textoLlantas,
        },
      ];

      respuestaIA = await openai.chat.completions.create({
        model: process.env.OPENAI_MODEL || 'gpt-4',
        messages: contexto2,
        temperature: 0.7,
      });

      textoGenerado = respuestaIA.choices?.[0]?.message?.content || '...';
    }
  }

  const textoFinal = textoGenerado.replace(/\[buscarInventarioCliente\([^\]]*\)\]/g, '');
  if (!textoFinal || textoFinal.trim() === '') {
    console.warn('‚ö†Ô∏è El textoFinal est√° vac√≠o. Se omitir√° el env√≠o al usuario.');
    return { statusCode: 200, body: 'Mensaje vac√≠o ignorado' };
  }

  await fetch(
    `https://graph.facebook.com/v17.0/me/messages?access_token=${process.env.FACEBOOK_PAGE_ACCESS_TOKEN}`,
    {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ recipient: { id: psid }, sender_action: 'typing_on' }),
    }
  );

  const delayMs = Math.min(4000, textoFinal.length * 30);
  await delay(delayMs);

  await fetch(
    `https://graph.facebook.com/v17.0/me/messages?access_token=${process.env.FACEBOOK_PAGE_ACCESS_TOKEN}`,
    {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ recipient: { id: psid }, message: { text: textoFinal } }),
    }
  );

  const convId = nuevaConversacion?.conversacion_id;
  await supabase.from('mensajes').insert({
    cliente_id: clienteId,
    mensaje: textoFinal,
    quien_hablo: 'asistente',
    conversacion_id: convId,
    sender_id: psid,
  });

  console.log('‚úÖ Respuesta del bot guardada.');
  return { statusCode: 200, body: 'OK' };
};